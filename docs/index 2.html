<html>
<head>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/85/three.min.js"></script>
</head>
<body>

	<video id="video" loop webkit-playsinline style="display:none">
		<source src="test.mov">
	</video>

	<script id="fragShader" type="shader-code">
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D videoTexture;

		uniform float time;
		uniform int iFrame;
		void main() {
			vec2 st = gl_FragCoord.xy / iResolution;
			vec2 uv = st;
			uv *= 0.998;

			vec4 sum = texture2D(bufferTexture, uv);
			vec4 src = texture2D(videoTexture, uv);
			sum.rgb = mix(sum.rbg, src.rgb, 0.1);
			gl_FragColor = sum;
		 	
		 }
	</script>

	<script id="fragmentShader_buffer_A" type="x-shader/x-fragment">
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		//varying vec2 vUv;

		uniform float iTime;
		uniform int iFrame;

	/*
		//Fluid Algorithm  https://www.shadertoy.com/view/MtdBDB
		vec2 R;
		float N;

		vec4 T ( vec2 U ) {
			return texture2D(bufferTexture,U/R);
		}

		float X (vec2 U0, vec2 U, vec2 U1, inout vec4 Q, in vec2 r) {
			vec2 V = U + r, u = T(V).xy,
				V0 = V - u,
				V1 = V + u;
			float P = T (V0).z, rr = length(r);
			Q.xy -= r*(P-Q.z)/rr/N;
			return (0.5*(length(V0-U0)-length(V1-U1))+P)/N;
		}

		float ln (vec2 p, vec2 a, vec2 b) { // returns distance to line segment for mouse input
			return length(p-a-(b-a)*clamp(dot(p-a,b-a)/dot(b-a,b-a),0.,1.));
		}

		void main()
		{   
			vec4 Q;
			vec2 U = gl_FragCoord.xy;

			R = iResolution.xy;
			vec2 U0 = U - T(U).xy,
				U1 = U + T(U).xy;
			float P = 0.;
			Q = T(U0);
			N = 4.;
			P += X (U0,U,U1,Q, vec2( 1., 0.) );
			P += X (U0,U,U1,Q, vec2( 0.,-1.) );
			P += X (U0,U,U1,Q, vec2(-1., 0.) );
			P += X (U0,U,U1,Q, vec2( 0., 1.) );
			Q.z = P;
			if (iFrame < 1) Q = vec4(0.);
			if (U.x < 1.||U.y < 1.||R.x-U.x < 1.||R.y-U.y < 1.) Q.xy *= 0.;
			
			if (length(U-vec2(0.1,0.5)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(.5,-.3);
			if (length(U-vec2(0.7,0.3)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(-.6,.3);
			if (length(U-vec2(0.2,0.2)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(.4,.6);
			if (length(U-vec2(0.7,0.5)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(-.1,-.3);
			if (length(U-vec2(0.5,0.6)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(0,-.7);
			
			//vec4 mo = texture2D(iChannel2,vec2(0));
			vec4 mo = vec4(0.);
			float l = ln(U,mo.xy,mo.zw);
			if (mo.z > 0. && l < 10.) {
				Q.xyz += vec3((10.-l)*(mo.xy-mo.zw)/R.y,(10.-l)*(length(mo.xy-mo.zw)/R.y)*0.02);
			}
			gl_FragColor = Q;
		}
		*/
		void main()
		{
			gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
		}
	  </script>

	  <script id="fragmentShader_buffer_B" type="x-shader/x-fragment">
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		//varying vec2 vUv;

		uniform float iTime;
		uniform int iFrame;

		 void main()
		{
			gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0);
		}
	  </script>

	  <script id="fragmentShader_buffer_C" type="x-shader/x-fragment">
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		//varying vec2 vUv;

		uniform float iTime;
		uniform int iFrame;

		 void main()
		{
			gl_FragColor = vec4(0.0, 0.0, 1.0, 1.0);
		}
	  </script>


	  <script id="fragmentShader_image" type="x-shader/x-fragment">
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		//varying vec2 vUv;

		//#define iChannel0 bufferTexture

		uniform float iTime;
		uniform int iFrame;


		 // straight sampling from img or buffer
		 void main()
		{
			vec4 tex = texture2D(bufferTexture, gl_FragCoord.xy / iResolution.xy);
			gl_FragColor = tex;

			//vec4 img = texture2D(imgTexture, gl_FragCoord.xy / iResolution.xy);
			//gl_FragColor = mix(tex.rgb, img.rgb, 0.5);
			vec2 st = gl_FragCoord.xy / iResolution.xy;
			if(st.x<0.25) gl_FragColor = vec4(1,1,1,1);
			
			//gl_FragColor = vec4(0.,0.,1.,1.);
		}

		
	  </script>


	<script>
		var scene;
		var camera;
		var buffercamera;

		var renderer;
		var bufferScene;
		var bufferScene_A;

		var textureA;
		var textureB;
		var textureC;
		var textureD;
		var textureImage;

		var bufferMaterial;
		var bufferMaterial_A;
		var bufferObject_A;

		var plane;
		var bufferObject;

		var finalMaterial;
		var quad;
        var video;
		var videoTexture;
		
		const width = window.innerWidth;
		const height = window.innerHeight;
		const rtWidth = window.innerWidth;
		const rtHeight =  window.innerHeight;


		function init() {
			//Create buffer textures
			textureA = new THREE.WebGLRenderTarget( rtWidth, rtHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			textureB = new THREE.WebGLRenderTarget( rtWidth, rtHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			textureC = new THREE.WebGLRenderTarget( rtWidth, rtHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			textureD = new THREE.WebGLRenderTarget( rtWidth, rtHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
		}

		function sceneSetup(){
			scene = new THREE.Scene();
			camera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
			camera.position.z = 2;

			// create fianl texture
			textureImage = new THREE.WebGLRenderTarget( rtWidth, rtHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			//finalMaterial =  new THREE.MeshBasicMaterial({map: textureImage.texture});
			finalMaterial = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA.texture },
				 iResolution : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},
				 //Keeps the resolution
				 //videoTexture: {type: "t", value: videoTexture },
				 imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
				 iTime: {type:"f",value:Math.random()*Math.PI*2+Math.PI},
				 iFrame: {type:"i",value: 0}
				},
				//fragmentShader: document.getElementById( 'fragShader' ).innerHTML
				fragmentShader: document.getElementById( 'fragmentShader_image' ).innerHTML
			} );

			plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight );
			quad = new THREE.Mesh( plane, finalMaterial );
			scene.add(quad);

			renderer = new THREE.WebGLRenderer();
			renderer.setSize( window.innerWidth, window.innerHeight );
			document.body.appendChild( renderer.domElement );
		}

		/*
		function videoTextureSetup() {
			video = document.getElementById( 'video' );
			videoTexture = new THREE.VideoTexture( video );

			videoTexture.minFilter = THREE.LinearFilter;
			videoTexture.magFilter = THREE.LinearFilter;
			videoTexture.format = THREE.RGBFormat;
		}
		*/

		


		function bufferTextureSetup(){
			buffercamera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
			buffercamera.position.z = 2;
			//Create buffer scene
			bufferSceneA = new THREE.Scene();
			bufferSceneB = new THREE.Scene();
			bufferSceneC = new THREE.Scene();

			//Pass texture to shader
			bufferMaterial_A = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA.texture },
				 iResolution : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},
				 //Keeps the resolution
				 //videoTexture: {type: "t", value: videoTexture },
				 imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
				 iTime: {type:"f",value:Math.random()*Math.PI*2+Math.PI},
				 iFrame: {type:"i",value: 0}
				},
				//fragmentShader: document.getElementById( 'fragShader' ).innerHTML
				fragmentShader: document.getElementById( 'fragmentShader_buffer_A' ).innerHTML
			} );
			//Pass texture to shader
			bufferMaterial_B = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA.texture },
				 iResolution : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},
				 //Keeps the resolution
				 //videoTexture: {type: "t", value: videoTexture },
				 imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
				 iTime: {type:"f",value:Math.random()*Math.PI*2+Math.PI},
				 iFrame: {type:"i",value: 0}
				},
				//fragmentShader: document.getElementById( 'fragShader' ).innerHTML
				fragmentShader: document.getElementById( 'fragmentShader_buffer_B' ).innerHTML
			} );
			//Pass texture to shader
			bufferMaterial_C = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA.texture },
				 iResolution : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},
				 //Keeps the resolution
				 //videoTexture: {type: "t", value: videoTexture },
				 imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
				 iTime: {type:"f",value:Math.random()*Math.PI*2+Math.PI},
				 iFrame: {type:"i",value: 0}
				},
				//fragmentShader: document.getElementById( 'fragShader' ).innerHTML
				fragmentShader: document.getElementById( 'fragmentShader_buffer_C' ).innerHTML
			} );

			bufferObject = new THREE.Mesh( plane, bufferMaterial_A );
			bufferSceneA.add(bufferObject);
			bufferObject = new THREE.Mesh( plane, bufferMaterial_B );
			bufferSceneB.add(bufferObject);
			bufferObject = new THREE.Mesh( plane, bufferMaterial_C );
			bufferSceneC.add(bufferObject);
		}

	
		//Initialize the Threejs scene that will render to the screen
		init();
		//videoTextureSetup();
		sceneSetup();
		bufferTextureSetup(); //Setup the frame buffer scenes we're going to be rendering to instead of the screen
		


		function render() {
		  requestAnimationFrame( render );
		  
		  // Make shader on quad BufferA - change input buffers - Draw bufferScene to textureA
		  renderer.setRenderTarget(textureA);
		  renderer.render(bufferSceneA,buffercamera,textureA,true);
		  //finalMaterial.uniforms.bufferTexture.value = textureA.texture;	// test that it gets passed into image
		  renderer.setRenderTarget(null);

		  // Make shader on quad BufferB - change input buffers - Draw bufferScene to textureB
		  renderer.setRenderTarget(textureB);
		  renderer.render(bufferSceneB,buffercamera,textureB,true);
		  //finalMaterial.uniforms.bufferTexture.value = textureB.texture;	// test that it gets passed into image
		  renderer.setRenderTarget(null);

		  // Make shader on quad BufferC - change input buffers - Draw bufferScene to textureC
		  renderer.setRenderTarget(textureC);
		  renderer.render(bufferSceneC,buffercamera,textureC,true);
		  //finalMaterial.uniforms.bufferTexture.value = textureC.texture;	// test that it gets passed into image
		  renderer.setRenderTarget(null);

		  //Update uniforms
		  bufferMaterial_A.uniforms.iTime.value += 0.01;
		  bufferMaterial_A.uniforms.iFrame.value += 1;
		  bufferMaterial_B.uniforms.iTime.value += 0.01;
		  bufferMaterial_B.uniforms.iFrame.value += 1;
		  bufferMaterial_C.uniforms.iTime.value += 0.01;
		  bufferMaterial_C.uniforms.iFrame.value += 1;

		  finalMaterial.uniforms.bufferTexture.value = textureA.texture;	// test that it gets passed into image
		  //Finally, draw to the screen
		  //quad.material.map = textureA.texture;
		  //quad.material.map = textureImage.texture;
		  renderer.render( scene, camera );

		}
		render();



	</script>
</body>
</html>

