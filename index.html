<html>

<head>
	<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/85/three.min.js"></script> -->
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r125/three.min.js"></script>
</head>

<body>

	<video id="video" loop webkit-playsinline style="display:none">
		<source src="test.mov">
	</video>
	<script id="vertexShader" type="x-shader/x-vertex">

		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		varying vec2 vUv;
		uniform sampler2D iChannel0;
		uniform sampler2D iChannel1;
		uniform sampler2D iChannel2;
		uniform float iTime;
		uniform int iFrame;
		uniform vec4 iMouse;
  
		void main()	{
		  //gl_Position = vec4(position, 1.0 );
		  vUv = uv;
		  gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
		}
	  </script>

	<script id="fragShader" type="shader-code">
		#extension GL_OES_standard_derivatives : enable
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D videoTexture;
		varying vec2 vUv;

		uniform float time;
		uniform int iFrame;
		uniform vec4 iMouse;

		void main() {
			vec2 st = gl_FragCoord.xy / iResolution;
			vec2 uv = st;
			uv *= 0.998;

			vec4 sum = texture2D(bufferTexture, uv);
			vec4 src = texture2D(videoTexture, uv);
			sum.rgb = mix(sum.rbg, src.rgb, 0.1);
			gl_FragColor = sum;
		 	
		 }
	</script>

	<script id="fragmentShader_buffer_A" type="x-shader/x-fragment">
		#extension GL_OES_standard_derivatives : enable
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		varying vec2 vUv;

		uniform sampler2D iChannel0;
		uniform sampler2D iChannel1;
		uniform sampler2D iChannel2;

		uniform float iTime;
		uniform int iFrame;
		uniform vec4 iMouse;
		vec4 fragColor;
		
		/*
		void main()
		{
			vec2 uv = gl_FragCoord.xy / iResolution.xy;
			vec4 tex = texture2D(iChannel0, uv);
			gl_FragColor = tex;
			if (uv.x < 0.2) {gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);}
			//gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
		}
		*/

		//Fluid Algorithm  https://www.shadertoy.com/view/MtdBDB
		vec2 R;
		float N;
		vec4 Q;
		vec2 U;

		vec4 T ( vec2 U ) {
			return texture2D(iChannel0,U/R);
		}

		float X (vec2 U0, vec2 U, vec2 U1, inout vec4 Q, in vec2 r) {
			vec2 V = U + r, u = T(V).xy,
				V0 = V - u,
				V1 = V + u;
			float P = T (V0).z, rr = length(r);
			Q.xy -= r*(P-Q.z)/rr/N;
			return (0.5*(length(V0-U0)-length(V1-U1))+P)/N;
		}

		float ln (vec2 p, vec2 a, vec2 b) { // returns distance to line segment for mouse input
			return length(p-a-(b-a)*clamp(dot(p-a,b-a)/dot(b-a,b-a),0.,1.));
		}

		void main()
		{   
			U = gl_FragCoord.xy;
			R = iResolution.xy;
			vec2 U0 = U - T(U).xy;
			vec2 U1 = U + T(U).xy;
			float P = 0.;
			Q = T(U0);
			N = 4.;
			P += X (U0,U,U1,Q, vec2( 1., 0.) );
			P += X (U0,U,U1,Q, vec2( 0.,-1.) );
			P += X (U0,U,U1,Q, vec2(-1., 0.) );
			P += X (U0,U,U1,Q, vec2( 0., 1.) );
			Q.z = P;
			if (iFrame < 1) Q = vec4(0.); // start transparent
			if (U.x < 1.||U.y < 1.||R.x-U.x < 1.||R.y-U.y < 1.) Q.xy *= 0.;
			
			if (length(U-vec2(0.1,0.5)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(.5,-.3);
			if (length(U-vec2(0.7,0.3)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(-.6,.3);
			if (length(U-vec2(0.2,0.2)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(.4,.6);
			if (length(U-vec2(0.7,0.5)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(-.1,-.3);
			if (length(U-vec2(0.5,0.6)*R) < .03*R.y) 
				Q.xy= Q.xy*.9+.1*vec2(0,-.7);
			
			vec4 mo = texture2D(iChannel2,vec2(0));
			//vec4 mo = vec4(0.);
			float l = ln(U,mo.xy,mo.zw);
			if (mo.z > 0. && l < 10.) {
				Q.xyz += vec3((10.-l)*(mo.xy-mo.zw)/R.y,(10.-l)*(length(mo.xy-mo.zw)/R.y)*0.02);
			}
			gl_FragColor = Q;
		}
		
	  </script>


	<script id="fragmentShader_buffer_B" type="x-shader/x-fragment">
		#extension GL_OES_standard_derivatives : enable
		uniform vec2 iResolution;			//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		varying vec2 vUv;
		uniform sampler2D iChannel0;
		uniform sampler2D iChannel1;
		uniform sampler2D iChannel2;

		uniform float iTime;
		uniform int iFrame;
		uniform vec4 iMouse;
		vec4 fragColor;

		/*
		 void main()
		{
			gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0);
		}
		*/

		// Voronoi based particle tracking
		vec2 R;
		float N;
		vec4 Q;
		vec2 U;

		vec4 T ( vec2 U ) {return texture2D(iChannel0, U/R);}
		vec4 P ( vec2 U ) {return texture2D(iChannel1, U/R);}

		void swap (vec2 U, inout vec4 Q, vec2 u) {
			vec4 p = P(U+u);
			float dl = length(U-Q.xy) - length(U-p.xy);
			float e = .1;
			// allows for probabistic reproduction
			Q = mix(Q,p,0.5+0.5*sign(floor(1e5*dl)));//the value next to dl adjusts the proabability of reproduction
			
			//uncomment and comment the line above to make it not self healing 
			//Q = mix(Q,p,dl>0.?1.:0.);
		}
		float ln (vec2 p, vec2 a, vec2 b) { // returns distance to line segment for mouse input
			return length(p-a-(b-a)*clamp(dot(p-a,b-a)/dot(b-a,b-a),0.,1.));
		}

		//void mainImage( out vec4 Q, in vec2 U )
		void main()
		{   
			U = gl_FragCoord.xy;
			R = iResolution.xy;
			// go back through the fluid and test the neighbors
			//  for the closest particles
			U = U-T(U).xy;
			Q = P(U);
			swap(U,Q,vec2(1,0));
			swap(U,Q,vec2(0,1));
			swap(U,Q,vec2(0,-1));
			swap(U,Q,vec2(-1,0));
		
			
			// add color from the jets in the fluid
			if ((length(Q.xy-vec2(0.1,0.5)*R) < .02*R.y))
				Q.zw = vec2(1,1);
			if ((length(Q.xy-vec2(0.7,0.3)*R) < .02*R.y))
				Q.zw = vec2(3,3);
			if ((length(Q.xy-vec2(0.2,0.2)*R) < .02*R.y))
				Q.zw = vec2(6,5);
			if (length(Q.xy-vec2(0.7,0.5)*R) < .02*R.y)
				Q.zw = vec2(2,7);
			if (length(Q.xy-vec2(0.5,0.6)*R) < .02*R.y) 
				Q.zw = vec2(5,4);
			
			vec4 mo = texture2D(iChannel2,vec2(0.));					// MUST SAMPLE FROM BUFFER C
			if (mo.z > 0. && ln(U,mo.xy,mo.zw) < 10.)
			{	
				Q = vec4(U,1,3.*sin(.4*iTime));
			}
		
			// advect this particle with the fluid
			Q.xy = Q.xy + T(Q.xy).xy;
			if (iFrame < 1) Q = vec4(floor(U/10.+0.5)*10.,0.2,-.1);

			//Q = mo;
			gl_FragColor = Q;
		}
	  </script>

	<script id="fragmentShader_buffer_C" type="x-shader/x-fragment">
		#extension GL_OES_standard_derivatives : enable
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		varying vec2 vUv;
		uniform sampler2D iChannel0;
		uniform sampler2D iChannel1;
		uniform sampler2D iChannel2;

		uniform float iTime;
		uniform int iFrame;
		uniform vec4 iMouse;
		vec4 fragColor;

		// keep track of mouse
		//void mainImage( out vec4 fragColor, in vec2 fragCoord )
		void main()
		{
			//vec4 p = texture2D(iChannel0, gl_FragCoord.xy/iResolution.xy);
			vec4 p = texture2D(iChannel0, vUv); // is same

			// if mouse is clicked and
			// if current mousePos x is not 0 - mousePos is actually full pixel range w h
			if (iMouse.z>0.) {
				// check if blue channel was not 0
				if (p.z>0.)
					fragColor =  vec4(iMouse.xy,p.xy);			// be yellow from (w,h,0->1,0->1)
				// if mousepos in previous frame was not clicked - is black
				else
					fragColor =  vec4(iMouse.xy,iMouse.xy);		// be white
			}
			else fragColor = vec4(-iResolution.xy,-iResolution.xy);		// be black
			gl_FragColor = fragColor;

			/*
			// CHECKS
			//gl_FragColor = vec4(iMouse.z/iResolution.x, 0.,0.,1.);
			vec2 uv = gl_FragCoord.xy/iResolution.xy;
			if (uv.x > 0.5)
				gl_FragColor = p;
			
			// mouse pos if mouse was mapped 0-1
			vec2 uv = (gl_FragCoord.xy/iResolution.xy);
			//gl_FragColor = vec4(vUv.x, vUv.y, 0., 1.);
			//gl_FragColor = vec4(uv.x, uv.y, 0., 1.);

			float x = iMouse.x/iResolution.x;           // from external
			float y = ((iMouse.y/iResolution.y) -1. ) * -1.;
			float space = 0.01;
			
			if (uv.x > x-space-0.005 && uv.x < x+space+0.005 && (uv.y > y-space-0.005 && uv.y < y+space+0.005 ))
				gl_FragColor = vec4(0.,0.,0.,1.);
			if (uv.x > x-space && uv.x < x+space && (uv.y > y-space && uv.y < y+space ))
				gl_FragColor = vec4(1.);
			*/
		}

		/*
		 void main()
		{
			gl_FragColor = vec4(0.0, 0.0, 1.0, 1.0);
		}
		*/
	  </script>


	<script id="fragmentShader_image" type="x-shader/x-fragment">
		#extension GL_OES_standard_derivatives : enable
		uniform vec2 iResolution;	//The width and height of our screen
		uniform sampler2D bufferTexture;	//Our input texture
		uniform sampler2D imgTexture;
		varying vec2 vUv;
		uniform sampler2D iChannel0;
		uniform sampler2D iChannel1;
		uniform sampler2D iChannel2;

		uniform float iTime;
		uniform int iFrame;
		vec4 fragColor;

		
		 // straight sampling from img or buffer
		 void main()
		{
			//vec4 tex = texture2D(bufferTexture, gl_FragCoord.xy / iResolution.xy);
			vec4 tex = texture2D(iChannel0, vUv);
			gl_FragColor = tex;

			//vec4 img = texture2D(imgTexture, gl_FragCoord.xy / iResolution.xy);
			//gl_FragColor = mix(tex.rgb, img.rgb, 0.5);
			//vec2 uv = gl_FragCoord.xy / iResolution.xy;
			//if(uv.x<0.25) gl_FragColor = vec4(1,1,1,1);
			
			//gl_FragColor = vec4(0.,0.,1.,1.);
		}
		
		
		/*
		// concept for voronoi tracking orginally from use stb
		//Render particles
		vec2 R;
		vec2 U;
		vec4 C;

		//vec4 T ( vec2 U ) {return texture2D(iChannel0,U/R);}
		//vec4 P ( vec2 U ) {return texture2D(iChannel1,U/R);}

		vec4 T ( vec2 U ) {return texture2D(iChannel0,vUv);}
		vec4 P ( vec2 U ) {return texture2D(iChannel1,vUv);}
		vec4 B ( vec2 U ) {return texture2D(iChannel2,vUv);}

		//void mainImage( out vec4 C, in vec2 U )
		void main() 
		{	
			U = gl_FragCoord.xy;
			R = iResolution.xy;
			C = P(U);

			
			vec2 	n = P(U+vec2(0,1)).xy;
			vec2 	e = P(U+vec2(1,0)).xy;
			vec2 	s = P(U-vec2(0,1)).xy;
			vec2 	w = P(U-vec2(1,0)).xy;
			float d = (length(n-C.xy)-1.+
				length(e-C.xy)-1.+
				length(s-C.xy)-1.+
				length(w-C.xy)-1.);

			
			// music based mask
			//float m1 = 2.*texture(iChannel2,vec2(abs(0.3*C.w),0.)).x,
			//      m2 = 1.5*texture(iChannel2,vec2(abs(0.3*C.z),0.)).x;
			//float p = smoothstep(2.5,2.,length(C.xy-U));
			//C = 0.5-0.5*sin(.2*(1.+m1)*C.z*vec4(1)+.4*(3.+m2)*C.w*vec4(1,3,5,4));	// color
			//C *= 1.-clamp(.1*d,0.,1.);
			

			C = T(U);
			C = B(U);
			//U = U / R;
			//C = vec4(U.x,U.y, 0.,1.);
			gl_FragColor = C;
		}
		*/
	  </script>

	  
	<script>
		// THREE JS PROGRAM
		var scene;
		var camera;
		var buffercamera;

		var renderer;
		var bufferScene;
		var bufferScene_A;
		var bufferScene_B;
		var bufferScene_C;
		var bufferScene_D;

		var textureA;
		var textureB;
		var textureC;
		var textureD;
		var textureCC;
		var textureBB;
		var textureImage;

		var bufferMaterial;
		var bufferMaterial_A;
		var bufferMaterial_B;
		var bufferMaterial_C;
		var bufferMaterial_D;

		var bufferObject_A;
		var bufferObject_B;
		var bufferObject_C;
		var bufferObject_D;

		var plane;
		var plane_A;
		var plane_B;
		var plane_c;
		var plane_D;

		var finalMaterial;
		var quad;
		var video;
		var videoTexture;

		const width = window.innerWidth;
		const height = window.innerHeight;
		const rtWidth = window.innerWidth;
		const rtHeight = window.innerHeight;

		var iTime;
		var iFrame;
		const iMouse = new THREE.Vector4();
		var iMousePressed = false;
		var startTime = Date.now();
		var timeScalar = 1.;

		const PARAMS = {
			wrapS: THREE.ClampToEdgeWrapping, //THREE.RepeatWrapping,
			wrapT: THREE.ClampToEdgeWrapping, //THREE.RepeatWrapping,
			minFilter: THREE.LinearFilter,
			magFilter: THREE.NearestFilter, //THREE.LinearFilter,//
			format: THREE.RGBFormat,
			type: THREE.FloatType,
			stencilBuffer: false
		};

		function onMouseMove(event) {
			// calculate mouse position in normalized device coordinates
			// (-0.5 to +0.5) for both components
			//iMouse.x = ( event.clientX / window.innerWidth ) - 0.5;
			//iMouse.y = (( event.clientY / window.innerHeight ) - 0.5) * -1.;

			// calculate mouse position in normalized device coordinates
			// 0 - 1
			//iMouse.x = ( event.clientX / window.innerWidth );
			//iMouse.y = (( event.clientY / window.innerHeight ) - 1) * -1.;

			// no mapping - pixel coordinates width and height, but height is flipped
			iMouse.x = event.clientX;
			iMouse.y = height - (event.clientY); //1.0 - uv.y;
			//console.log(iMouse.x);
			//console.log(iMouse.y);
			//console.log(event.buttons);
			if (event.buttons > 0) {	// button is pressed
				//console.log("pressed");
				if (!iMousePressed) { 	// if it wasn't pressed last frame
					iMouse.z = iMouse.x;
					iMouse.w = iMouse.y;
					iMousePressed = true;
					console.log('iMouse.z');
					console.log(iMouse.z);
					console.log(iMouse.w);
				}
			}
			if (event.buttons == 0) {
				iMousePressed = false;
				iMouse.z = 0.;
				iMouse.w = 0.;
				console.log("not pressed");
			}
		}

		function init() {
			window.addEventListener('mousemove', onMouseMove, false);
			var elapsedMilliseconds = Date.now() - startTime;
        	//var elapsedSeconds = elapsedMilliseconds / 1000.;
        	iTime = elapsedMilliseconds * timeScalar;
			iFrame = 0;

			textureA = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			textureB = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			textureC = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			textureD = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			textureCC = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			textureBB = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
		}

		function sceneSetup() {
			console.log("Scene loaded -----------");
			scene = new THREE.Scene();
			camera = new THREE.OrthographicCamera(width / - 2, width / 2, height / 2, height / - 2, 1, 1000);
			camera.position.z = 2;

			// create final texture
			textureImage = new THREE.WebGLRenderTarget(rtWidth, rtHeight, PARAMS);
			//finalMaterial =  new THREE.MeshBasicMaterial({map: textureImage.texture});
			finalMaterial = new THREE.ShaderMaterial({
				uniforms: {
					bufferTexture: { type: "t", value: textureA.texture },
					iResolution: { type: 'v2', value: new THREE.Vector2(rtWidth, rtHeight) },
					imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					iChannel0: { type: "t", value: textureA.texture },
					iChannel1: { type: "t", value: textureBB.texture },
					iChannel2: { type: "t", value: textureCC.texture },
					iTime: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI },
					iFrame: { type: "i", value: 0 },
					iMouse: { type: "v4", value: new THREE.Vector4(iMouse.x, iMouse.y, iMouse.z, iMouse.w) }
				},
				vertexShader: document.getElementById('vertexShader').textContent,
				fragmentShader: document.getElementById('fragmentShader_image').textContent
			});			

			plane = new THREE.PlaneBufferGeometry(rtWidth, rtHeight);
			quad = new THREE.Mesh(plane, finalMaterial);
			scene.add(quad);

			renderer = new THREE.WebGLRenderer({antialias: true});
			renderer.setSize(rtWidth, rtHeight);
			document.body.appendChild(renderer.domElement);
		}

		/*
		function videoTextureSetup() {
			video = document.getElementById( 'video' );
			videoTexture = new THREE.VideoTexture( video );

			videoTexture.minFilter = THREE.LinearFilter;
			videoTexture.magFilter = THREE.LinearFilter;
			videoTexture.format = THREE.RGBFormat;
		}
		*/


		function bufferTextureSetup() {
			buffercamera = new THREE.OrthographicCamera(width / - 2, width / 2, height / 2, height / - 2, 1, 1000);
			buffercamera.position.z = 2;
			//Create buffer scene
			bufferSceneA = new THREE.Scene();
			bufferSceneB = new THREE.Scene();
			bufferSceneC = new THREE.Scene();
			bufferSceneD = new THREE.Scene();

			//Pass texture to shader
			bufferMaterial_A = new THREE.ShaderMaterial({
				uniforms: {
					//bufferTexture: { type: "t", value: textureA.texture },
					iResolution: { type: 'v2', value: new THREE.Vector2(rtWidth, rtHeight) },
					imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					//iChannel0: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					iChannel0: { type: "t", value: textureD.texture },
					//iChannel1: { type: "t", value: textureB.texture },
					iChannel2: { type: "t", value: textureC.texture },
					iTime: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI },
					iFrame: { type: "i", value: 0 },
					iMouse: { type: "v4", value: new THREE.Vector4(iMouse.x, iMouse.y, iMouse.z, iMouse.w) }
				},
				vertexShader: document.getElementById('vertexShader').textContent,
				fragmentShader: document.getElementById('fragmentShader_buffer_A').innerHTML
			});

			//Pass texture to shader
			bufferMaterial_B = new THREE.ShaderMaterial({
				uniforms: {
					bufferTexture: { type: "t", value: textureA.texture },
					iResolution: { type: 'v2', value: new THREE.Vector2(rtWidth, rtHeight) },
					imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					iChannel0: { type: "t", value: textureA.texture },
					iChannel1: { type: "t", value: textureBB.texture },
					iChannel2: { type: "t", value: textureC.texture },
					iTime: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI },
					iFrame: { type: "i", value: 0 },
					iMouse: { type: "v4", value: new THREE.Vector4(iMouse.x, iMouse.y, iMouse.z, iMouse.w) }
				}, 
				vertexShader: document.getElementById('vertexShader').textContent,
				fragmentShader: document.getElementById('fragmentShader_buffer_B').innerHTML
			});

			//Pass texture to shader
			bufferMaterial_C = new THREE.ShaderMaterial({
				uniforms: {
					bufferTexture: { type: "t", value: textureA.texture },
					iResolution: { type: 'v2', value: new THREE.Vector2(rtWidth, rtHeight) },
					imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					iChannel0: { type: "t", value: textureCC.texture },
					//iChannel1: { type: "t", value: textureB.texture },
					//iChannel2: { type: "t", value: textureC.texture },
					iTime: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI },
					iFrame: { type: "i", value: 0 },
					iMouse: { type: "v4", value: new THREE.Vector4(iMouse.x, iMouse.y, iMouse.z, iMouse.w) }
				}, 
				vertexShader: document.getElementById('vertexShader').textContent,
				fragmentShader: document.getElementById('fragmentShader_buffer_C').innerHTML
			});
			bufferMaterial_D = new THREE.ShaderMaterial({
				uniforms: {
					//bufferTexture: { type: "t", value: textureA.texture },
					iResolution: { type: 'v2', value: new THREE.Vector2(rtWidth, rtHeight) }, 
					imgTexture: { type: "t", value: new THREE.TextureLoader().load('textures/img.png') },
					iChannel0: { type: "t", value: textureA.texture },
					//iChannel1: { type: "t", value: textureB.texture },
					iChannel2: { type: "t", value: textureC.texture },
					iTime: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI },
					iFrame: { type: "i", value: 0 },
					iMouse: { type: "v4", value: new THREE.Vector4(iMouse.x, iMouse.y, iMouse.z, iMouse.w) }
				}, 
				vertexShader: document.getElementById('vertexShader').textContent,
				fragmentShader: document.getElementById('fragmentShader_buffer_A').innerHTML
			});
			/*
			bufferMaterial_A.material.extensions.derivatives = true;
			bufferMaterial_B.material.extensions.derivatives = true;
			bufferMaterial_C.material.extensions.derivatives = true;
			bufferMaterial_D.material.extensions.derivatives = true;
			*/
			plane_A = new THREE.PlaneBufferGeometry(rtWidth, rtHeight);
			plane_B = new THREE.PlaneBufferGeometry(rtWidth, rtHeight);
			plane_C = new THREE.PlaneBufferGeometry(rtWidth, rtHeight);
			plane_D = new THREE.PlaneBufferGeometry(rtWidth, rtHeight);
			bufferObject_A = new THREE.Mesh(plane_A, bufferMaterial_A);
			bufferSceneA.add(bufferObject_A);
			bufferObject_B = new THREE.Mesh(plane_B, bufferMaterial_B);
			bufferSceneB.add(bufferObject_B);
			bufferObject_C = new THREE.Mesh(plane_C, bufferMaterial_C);
			bufferSceneC.add(bufferObject_C);
			bufferObject_D = new THREE.Mesh(plane_D, bufferMaterial_D);
			bufferSceneD.add(bufferObject_D);
		}


		//Initialize the Threejs scene that will render to the screen
		init();
		//videoTextureSetup();
		sceneSetup();
		bufferTextureSetup(); //Setup the frame buffer scenes we're going to be rendering to instead of the screen


		function render() {
			requestAnimationFrame(render);

			// Make shader on quad BufferA - change input buffers - Draw bufferScene to textureA
			renderer.setRenderTarget(textureA);
			//renderer.render(bufferSceneA,buffercamera,textureA,true);
			renderer.render(bufferSceneA, buffercamera);
			//finalMaterial.uniforms.bufferTexture.value = textureA.texture;	// test that it gets passed into image
			renderer.setRenderTarget(null);

			// Make shader on quad BufferB - change input buffers - Draw bufferScene to textureB
			renderer.setRenderTarget(textureB);
			//renderer.render(bufferSceneB,buffercamera,textureB,true);
			renderer.render(bufferSceneB, buffercamera);
			//finalMaterial.uniforms.bufferTexture.value = textureB.texture;	// test that it gets passed into image
			renderer.setRenderTarget(null);
			textureBB = textureB;

			// Make shader on quad BufferC - change input buffers - Draw bufferScene to textureC
			renderer.setRenderTarget(textureC);
			//renderer.render(bufferSceneC,buffercamera,textureC,true);
			renderer.render(bufferSceneC, buffercamera);
			//finalMaterial.uniforms.bufferTexture.value = textureC.texture;	// test that it gets passed into image
			renderer.setRenderTarget(null);
			textureCC = textureC;

			// Make shader on quad BufferC - change input buffers - Draw bufferScene to textureC
			renderer.setRenderTarget(textureD);
			//renderer.render(bufferSceneD,buffercamera,textureD,true);
			renderer.render(bufferSceneD, buffercamera);
			//finalMaterial.uniforms.bufferTexture.value = textureD.texture;	// test that it gets passed into image
			renderer.setRenderTarget(null);

			/*
			bufferMaterial_A.uniforms.iChannel0.value = textureD.texture;
			bufferMaterial_B.uniforms.iChannel0.value = textureA.texture;
			bufferMaterial_B.uniforms.iChannel1.value = textureBB.texture;
			finalMaterial.uniforms.iChannel0.value = textureA.texture;
			finalMaterial.uniforms.iChannel1.value = textureBB.texture;
			*/

			bufferMaterial_A.uniforms.iMouse.value = iMouse;
			bufferMaterial_B.uniforms.iMouse.value = iMouse;
			bufferMaterial_C.uniforms.iMouse.value = iMouse;
			bufferMaterial_D.uniforms.iMouse.value = iMouse;


			bufferMaterial_A.uniforms.iTime.value = iTime;
			bufferMaterial_A.uniforms.iFrame.value = iFrame;
			bufferMaterial_B.uniforms.iTime.value = iTime;
			bufferMaterial_B.uniforms.iFrame.value = iFrame;
			bufferMaterial_C.uniforms.iTime.value = iTime;
			bufferMaterial_C.uniforms.iFrame.value = iFrame;
			bufferMaterial_D.uniforms.iTime.value = iTime;
			bufferMaterial_D.uniforms.iFrame.value = iFrame;
			finalMaterial.uniforms.iTime.value = iTime;
			finalMaterial.uniforms.iFrame.value = iFrame;

			//Update uniforms
			var elapsedMilliseconds = Date.now() - startTime;
        	var elapsedSeconds = elapsedMilliseconds / 1000.;
        	iTime = elapsedMilliseconds * timeScalar; 			//60. * elapsedSeconds;
			//iTime += 1.;
			iFrame += 1;
			//finalMaterial.uniforms.bufferTexture.value = textureA.texture;	// test that it gets passed into image

			
			textureA.needsUpdate = true;
			textureB.needsUpdate = true;
			textureC.needsUpdate = true;
			textureD.needsUpdate = true;
			textureCC.needsUpdate = true;
			textureBB.needsUpdate = true;
			

			//finalMaterial.uniforms.bufferTexture.value = tb.texture;//textureB.texture;	// test that it gets passed into image
			//finalMaterial.uniforms.bufferTexture.value = textureBB.texture;	// test that it gets passed into image
			finalMaterial.uniforms.iChannel0.value = textureA.texture;
			//Finally, draw to the screen
			//quad.material.map = textureA.texture;
			//quad.material.map = textureImage.texture;
			renderer.render(scene, camera);
		}
		render();
	</script>
</body>
</html>